{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55236c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Union, Tuple, Optional\n",
    "import yaml\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "sys.path.append(str(Path(__file__).resolve().parents[1] / \"features\"))\n",
    "from text_processor import TextProcessor\n",
    "# Import du TextProcessor\n",
    "# Option 1: Si text_processor.py est dans src/features\n",
    "\n",
    "\n",
    "# Option 2: Si text_processor.py est dans le même dossier que random_forest_model.py\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "# sys.path.append(str(Path(__file__).parent))\n",
    "# from text_processor import TextProcessor\n",
    "\n",
    "# Configure logger\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class RandomForestModel:\n",
    "    \"\"\"\n",
    "    Classe pour l'entraînement, l'évaluation et l'utilisation d'un modèle RandomForest\n",
    "    pour la classification de textes.\n",
    "    \"\"\"\n",
    "    def __init__(self, config_path: Union[str, Path] = None):\n",
    "        # Determine project root and default config path\n",
    "        project_root = Path(__file__).resolve().parents[2]\n",
    "        default_cfg = project_root / \"config\" / \"config.yaml\"\n",
    "        self.config_path = Path(config_path) if config_path else default_cfg\n",
    "        \n",
    "        # Load config\n",
    "        self.config = self._load_config(self.config_path)\n",
    "        \n",
    "        # Paths & params\n",
    "        self.input_file = project_root / self.config.get(\"processed_file\", \"data/processed/x_train_clean.csv\")\n",
    "        self.model_output = project_root / self.config.get(\"model_output\", \"models/randomforest.pkl\")\n",
    "        \n",
    "        # Model settings\n",
    "        model_cfg = self.config.get(\"model\", {})\n",
    "        self.test_size = model_cfg.get(\"test_size\", 0.2)\n",
    "        self.random_state = model_cfg.get(\"random_state\", 42)\n",
    "        \n",
    "        # RandomForest parameters\n",
    "        rf_params = model_cfg.get(\"random_forest\", {})\n",
    "        self.n_estimators = rf_params.get(\"n_estimators\", 100)\n",
    "        self.max_depth = rf_params.get(\"max_depth\", None)\n",
    "        self.min_samples_split = rf_params.get(\"min_samples_split\", 2)\n",
    "        self.class_weight = rf_params.get(\"class_weight\", \"balanced\")\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = None\n",
    "        self.text_processor = None\n",
    "        self.classes_ = None\n",
    "\n",
    "    def _load_config(self, path: Path) -> Dict[str, Any]:\n",
    "        \"\"\"Charge la configuration depuis un fichier YAML.\"\"\"\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                cfg = yaml.safe_load(f)\n",
    "                logger.info(f\"Configuration chargée depuis {path}\")\n",
    "                return cfg\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Impossible de charger {path}: {e}\\nUtilisation des valeurs par défaut.\")\n",
    "            return {}\n",
    "    \n",
    "    def _load_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Charge les données prétraitées depuis le fichier CSV.\"\"\"\n",
    "        logger.info(f\"Chargement des données depuis {self.input_file}\")\n",
    "        return pd.read_csv(self.input_file, encoding=\"utf-8\")\n",
    "    \n",
    "    def _prepare_data(self, data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Prépare les données pour l'entraînement en utilisant le TextProcessor\n",
    "        pour la vectorisation TF-IDF.\n",
    "        \"\"\"\n",
    "        logger.info(\"Préparation des données pour l'entraînement...\")\n",
    "        \n",
    "        X = data[\"text\"].values\n",
    "        y = data[\"label\"].values\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        # Split des données\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=self.test_size, random_state=self.random_state, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Vectorisation des textes avec le TextProcessor\n",
    "        logger.info(\"Initialisation et entraînement du TextProcessor...\")\n",
    "        self.text_processor = TextProcessor(self.config_path)\n",
    "        X_train_vec = self.text_processor.fit_transform(X_train)\n",
    "        X_test_vec = self.text_processor.transform(X_test)\n",
    "        \n",
    "        logger.info(f\"Données divisées: Train={X_train_vec.shape[0]}, Test={X_test_vec.shape[0]}\")\n",
    "        logger.info(f\"Dimension des features: {X_train_vec.shape[1]}\")\n",
    "        \n",
    "        return X_train_vec, X_test_vec, y_train, y_test\n",
    "    \n",
    "    def train(self, X_train: Optional[np.ndarray] = None, y_train: Optional[np.ndarray] = None) -> 'RandomForestModel':\n",
    "        if X_train is None or y_train is None:\n",
    "            data = self._load_data()\n",
    "            X_train_vec, X_test_vec, y_train, y_test = self._prepare_data(data)\n",
    "            # Si on a juste appelé train() sans arguments, on évalue aussi le modèle\n",
    "            self._train_model(X_train_vec, y_train)\n",
    "            self._evaluate_model(X_test_vec, y_test)\n",
    "        else:\n",
    "            # Si l'utilisateur a fourni explicitement X_train et y_train\n",
    "            self._train_model(X_train, y_train)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _train_model(self, X_train: np.ndarray, y_train: np.ndarray) -> None:\n",
    "    \n",
    "        logger.info(f\"Entraînement du modèle RandomForest avec {X_train.shape[0]} exemples\")\n",
    "        logger.info(f\"Paramètres: n_estimators={self.n_estimators}, max_depth={self.max_depth}\")\n",
    "        \n",
    "        self.model = RandomForestClassifier(\n",
    "            n_estimators=self.n_estimators,\n",
    "            max_depth=self.max_depth,\n",
    "            min_samples_split=self.min_samples_split,\n",
    "            class_weight=self.class_weight,\n",
    "            random_state=self.random_state,\n",
    "            n_jobs=-1  # Utiliser tous les cœurs disponibles\n",
    "        )\n",
    "        \n",
    "        self.model.fit(X_train, y_train)\n",
    "        logger.info(\"Entraînement du modèle terminé\")\n",
    "    \n",
    "    def evaluate(self, X_test: np.ndarray, y_test: np.ndarray) -> Dict[str, float]:\n",
    "\n",
    "        return self._evaluate_model(X_test, y_test)\n",
    "    \n",
    "    def _evaluate_model(self, X_test: np.ndarray, y_test: np.ndarray) -> Dict[str, float]:\n",
    "      \n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Le modèle n'a pas été entraîné. Appelez d'abord train().\")\n",
    "        \n",
    "        logger.info(f\"Évaluation du modèle sur {X_test.shape[0]} exemples...\")\n",
    "        \n",
    "        y_pred = self.model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        logger.info(f\"Accuracy: {accuracy:.4f}\")\n",
    "        logger.info(f\"F1 Score (weighted): {f1:.4f}\")\n",
    "        logger.info(\"\\nRapport de classification détaillé:\")\n",
    "        logger.info(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Confusion matrix\n",
    "        logger.info(\"\\nMatrice de confusion:\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        logger.info(f\"\\n{cm}\")\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'classification_report': classification_report(y_test, y_pred, output_dict=True)\n",
    "        }\n",
    "    \n",
    "    def predict(self, texts: Union[str, list, np.ndarray]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Prédit la classe pour un ou plusieurs textes.\n",
    "        \n",
    "        Args:\n",
    "            texts: Texte unique ou liste/array de textes à classifier\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Prédictions des classes\n",
    "        \"\"\"\n",
    "        if self.model is None or self.text_processor is None:\n",
    "            raise ValueError(\"Le modèle ou le processeur de texte n'a pas été initialisé. Appelez d'abord train() ou load().\")\n",
    "        \n",
    "        # Convert single text to array\n",
    "        if isinstance(texts, str):\n",
    "            texts = np.array([texts])\n",
    "        elif isinstance(texts, list):\n",
    "            texts = np.array(texts)\n",
    "        \n",
    "        # Transform text to TF-IDF features\n",
    "        X = self.text_processor.transform(texts)\n",
    "        \n",
    "        # Make predictions\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, texts: Union[str, list, np.ndarray]) -> np.ndarray:\n",
    "      \n",
    "        if self.model is None or self.text_processor is None:\n",
    "            raise ValueError(\"Le modèle ou le processeur de texte n'a pas été initialisé. Appelez d'abord train() ou load().\")\n",
    "        \n",
    "        # Convert single text to array\n",
    "        if isinstance(texts, str):\n",
    "            texts = np.array([texts])\n",
    "        elif isinstance(texts, list):\n",
    "            texts = np.array(texts)\n",
    "        \n",
    "        # Transform text to TF-IDF features\n",
    "        X = self.text_processor.transform(texts)\n",
    "        \n",
    "        # Make probabilistic predictions\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def save(self, output_path: Union[str, Path] = None) -> None:\n",
    "        \"\"\"\n",
    "        Sauvegarde le modèle et le processeur de texte dans un fichier.\n",
    "        \n",
    "        Args:\n",
    "            output_path: Chemin où sauvegarder le modèle (facultatif)\n",
    "        \"\"\"\n",
    "        if self.model is None or self.text_processor is None:\n",
    "            raise ValueError(\"Le modèle ou le processeur de texte n'a pas été initialisé. Appelez d'abord train() ou load().\")\n",
    "        \n",
    "        save_path = Path(output_path) if output_path else self.model_output\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        logger.info(f\"Sauvegarde du modèle et du processeur de texte dans {save_path}\")\n",
    "        \n",
    "        # Save both model and text processor\n",
    "        joblib.dump({\n",
    "            'model': self.model,\n",
    "            'text_processor_vectorizer': self.text_processor.vectorizer,\n",
    "            'classes_': self.classes_\n",
    "        }, save_path)\n",
    "        \n",
    "        logger.info(f\"Modèle sauvegardé avec succès dans {save_path}\")\n",
    "    \n",
    "    def load(self, input_path: Union[str, Path] = None) -> 'RandomForestModel':\n",
    "        \"\"\"\n",
    "        Charge un modèle préentraîné et son processeur de texte depuis un fichier.\n",
    "        \n",
    "        Args:\n",
    "            input_path: Chemin du fichier modèle à charger (facultatif)\n",
    "            \n",
    "        Returns:\n",
    "            self: Retourne l'instance de la classe pour permettre le chaînage des méthodes\n",
    "        \"\"\"\n",
    "        load_path = Path(input_path) if input_path else self.model_output\n",
    "        \n",
    "        logger.info(f\"Chargement du modèle depuis {load_path}\")\n",
    "        \n",
    "        # Load model and vectorizer\n",
    "        saved_data = joblib.load(load_path)\n",
    "        \n",
    "        self.model = saved_data['model']\n",
    "        self.classes_ = saved_data.get('classes_', self.model.classes_)\n",
    "        \n",
    "        # Create and initialize text processor\n",
    "        self.text_processor = TextProcessor(self.config_path)\n",
    "        self.text_processor.vectorizer = saved_data['text_processor_vectorizer']\n",
    "        \n",
    "        logger.info(f\"Modèle chargé avec succès: {self.model}\")\n",
    "        return self\n",
    "\n",
    "def train_and_save_model(config_path: Union[str, Path] = None) -> None:\n",
    "    \"\"\"\n",
    "    Fonction utilitaire pour entraîner et sauvegarder un modèle RandomForest.\n",
    "    \n",
    "    Args:\n",
    "        config_path: Chemin du fichier de configuration (facultatif)\n",
    "    \"\"\"\n",
    "    logger.info(\"Démarrage de l'entraînement du modèle RandomForest...\")\n",
    "    \n",
    "    try:\n",
    "        # Créer et entraîner le modèle\n",
    "        rf_model = RandomForestModel(config_path)\n",
    "        rf_model.train()  # Charge les données, entraîne et évalue le modèle\n",
    "        \n",
    "        # Sauvegarder le modèle et le vectoriseur\n",
    "        rf_model.save()\n",
    "        \n",
    "        logger.info(\"Processus d'entraînement terminé avec succès!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur durant l'entraînement du modèle: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Exécuter l'entraînement du modèle si le script est lancé directement\n",
    "    train_and_save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ea6fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('tfidf',\n",
      "                 TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
      "                ('clf', RandomForestClassifier(random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load(\"../models/random_forest_model.pkl\")\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
