{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9901cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decorators.py\n",
    "import time\n",
    "def timing(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        print(f\"{func.__name__} executed in {time.time() - start:.2f}s\")\n",
    "        return result\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f99529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fichiers d'entrée/sortie\n",
    "input_path = \"../data/raw/train.csv\"\n",
    "output_path = \"../data/processed/train_clean.csv\"\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def data_generator(file_path, chunk_size=10000):\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "        chunk.dropna(subset=['text', 'label'], inplace=True)\n",
    "        chunk['text'] = chunk['text'].astype(str).apply(preprocess_text)\n",
    "        yield chunk\n",
    "\n",
    "# Fonction pour traiter et sauvegarder les données dans le fichier final\n",
    "def process_data_stream(file_path, output_path):\n",
    "    first = True  # Pour vérifier si c'est le premier chunk\n",
    "    for chunk in data_generator(file_path):\n",
    "        chunk.to_csv(output_path, mode='a', index=False, header=first)  # Sauvegarde les données\n",
    "        first = False  # Après le premier chunk, ne plus écrire l'en-tête\n",
    "\n",
    "gen = data_generator(input_path, chunk_size=10000)\n",
    "first_chunk = next(gen)\n",
    "first_chunk.head()  # Affiche les premières lignes du premier chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8119ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data_stream(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223919ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from data_loader import data_generator  # ou ton code générateur\n",
    "\n",
    "# Chargement des données nettoyées\n",
    "gen = data_generator(\"../data/processed/train_clean.csv\", chunk_size=5000)\n",
    "X_list, y_list = [], []\n",
    "\n",
    "for chunk in gen:\n",
    "    X_list.extend(chunk[\"text\"])\n",
    "    y_list.extend(chunk[\"label\"])\n",
    "\n",
    "# Vectorisation TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vect = vectorizer.fit_transform(X_list)\n",
    "y = y_list\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement + suivi MLflow\n",
    "with mlflow.start_run():\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    preds = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.sklearn.log_model(clf, \"model\")\n",
    "    mlflow.log_param(\"model\", \"LogisticRegression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41edea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5000\n",
      "Modèle sauvegardé avec MLflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\MD3S-FP\\Semester 1\\Python Av\\Workspace python\\classification-commentaires\\.venv\\lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\MD3S-FP\\Semester 1\\Python Av\\Workspace python\\classification-commentaires\\.venv\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Création d'un jeu de données factice\n",
    "data = {'text': [\"I love programming\", \"Python is great\", \"I hate bugs\", \"Programming is fun\", \n",
    "                 \"I love solving problems\", \"Bugs are annoying\", \"Python is awesome\", \"Debugging is hard\"],\n",
    "        'label': [1, 1, 0, 1, 1, 0, 1, 0]}  # Classe 1: Positif, Classe 0: Négatif\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Séparer les données et les étiquettes\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Diviser en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Étape 1 : Prétraitement avec TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # Limite à 1000 mots les plus fréquents\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Étape 2 : Entraîner le modèle de régression logistique\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Prédictions sur les données de test\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Calcul de la précision du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Étape 3 : Suivi du modèle avec MLflow\n",
    "# Démarrer un suivi avec MLflow\n",
    "with mlflow.start_run():\n",
    "    # Log de l'accuracy\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    # Log du modèle\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    \n",
    "    # Log des paramètres du modèle (exemple de hyperparamètres)\n",
    "    mlflow.log_param(\"max_features\", 1000)\n",
    "\n",
    "    # Log du vecteur TF-IDF\n",
    "    # mlflow.log_artifact(\"tfidf_vectorizer.pkl\")  # Sauvegarde du vectorizer dans un fichier (si nécessaire)\n",
    "    \n",
    "    print(\"Modèle sauvegardé avec MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d0730cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"test_experiment\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"param1\", 5)\n",
    "    mlflow.log_metric(\"accuracy\", 0.89)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
