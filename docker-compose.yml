
version: '3'

services:

  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: model_api
    ports:
      - "8000:8000"
    env_file:
      - ./.env
    environment:
      - PYTHONPATH=/app
    command: ["python", "src/api/main.py"]
    volumes:
      - ./:/app
      - wandb_data:/app/models/wandb
  prometheus:
    image: prom/prometheus
    container_name: prometheus
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    ports:
      - "9090:9090"
  

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    ports:
      - "5000:5000"
    volumes:
      - ./mlflow:/mlflow
    environment:
      - MLFLOW_TRACKING_URI=http://localhost:5000
    command: mlflow server --host 0.0.0.0 --port 5000
  

  # model_training:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.train
  #   container_name: model_training
  #   env_file:
  #     - ./config/.env
  #   environment:
  #     - PYTHONPATH=/app
  #     - WANDB_MODE=online
  #     - PROMETHEUS_PUSHGATEWAY=prometheus_pushgateway:9091
  #   volumes:
  #     - wandb_data:/app/models/wandb
  #   networks:
  #     - monitoring_network
  #   depends_on:
  #     - prometheus



volumes:
  wandb_data:

# networks:
#   monitoring_network:
#     driver: bridge